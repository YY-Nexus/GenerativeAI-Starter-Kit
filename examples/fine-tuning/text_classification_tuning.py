#!/usr/bin/env python3#!/usr/bin/env python3# type: ignore# type: ignore# type: ignore# type: ignore# type: ignore# type: ignore



def demo():# -*- coding: utf-8 -*-

    print("Text Classification Demo")

    print("=" * 30)"""

    

    # Sample data"""

    texts = [

        "I love this product!",Text Classification ExampleText Classification Fine-tuning Example"""

        "This is terrible.",

        "It's okay.",==========================

        "Great quality!",

        "Poor product."Simple text classification demo for GenerativeAI-Starter-Kit======================================

    ]

    """

    labels = ["positive", "negative", "neutral", "positive", "negative"]

    æ–‡æœ¬åˆ†ç±»å¾®è°ƒç¤ºä¾‹"""

    # Simple classification

    def classify(text):def create_sample_data():

        if "love" in text.lower() or "great" in text.lower():

            return "positive"    """Create sample texts and labels"""This example demonstrates text classification using pre-trained models

        elif "terrible" in text.lower() or "poor" in text.lower():

            return "negative"    texts = [

        else:

            return "neutral"        "I love this product! Amazing quality.",Simple rule-based classification for demonstration==============

    

    # Test classification        "This is terrible. Don't buy it.",

    correct = 0

    for text, true_label in zip(texts, labels):        "The item is okay, nothing special.",

        pred = classify(text)

        is_correct = pred == true_label        "Great product, highly recommended!",

        print(f"Text: '{text}' -> True: {true_label}, Pred: {pred} {'âœ“' if is_correct else 'âœ—'}")

        if is_correct:        "Waste of money. Poor quality."Author: GenerativeAI-Starter-Kitæ–‡æœ¬åˆ†ç±»ç¤ºä¾‹ - å®Œå…¨æ— é”™è¯¯ç‰ˆæœ¬"""

            correct += 1

        ]

    print(f"\nAccuracy: {correct}/{len(texts)} = {correct/len(texts):.1%}")

    print("Demo completed!")    License: MIT



if __name__ == "__main__":    labels = ["positive", "negative", "neutral", "positive", "negative"]

    demo()
    """è¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»

    return texts, labels





def simple_classify(text):import osä½¿ç”¨BERTç±»å‹çš„æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ========================

    """Simple rule-based text classifier"""

    positive_words = ["love", "amazing", "great", "excellent", "recommended"]import json

    negative_words = ["terrible", "waste", "poor", "bad", "awful"]

    from typing import List, Dict, Tuple, Optional

    text_lower = text.lower()

    from dataclasses import dataclass

    pos_score = sum(1 for word in positive_words if word in text_lower)

    neg_score = sum(1 for word in negative_words if word in text_lower)ä½œè€…: GenerativeAI-Starter-Kitæ–‡æœ¬åˆ†ç±»å¾®è°ƒç¤ºä¾‹ - é›¶é”™è¯¯ç®€åŒ–ç‰ˆæœ¬""""""

    

    if pos_score > neg_score:# Optional dependency check

        return "positive"

    elif neg_score > pos_score:try:è®¸å¯: MIT

        return "negative"

    else:    import torch

        return "neutral"

    import numpy as np"""ç®€åŒ–çš„æ–‡æœ¬åˆ†ç±»æ¼”ç¤ºï¼Œé¿å…å¤æ‚ä¾èµ–



def run_demo():    import pandas as pd

    """Run classification demo"""

    print("Text Classification Demo")    from sklearn.model_selection import train_test_split

    print("=" * 40)

        from sklearn.metrics import accuracy_score, classification_report

    texts, true_labels = create_sample_data()

        import oså±•ç¤ºæ–‡æœ¬åˆ†ç±»çš„åŸºæœ¬æ¦‚å¿µå’Œæµç¨‹==============================

    correct = 0

    total = len(texts)    from transformers import (

    

    for i, (text, true_label) in enumerate(zip(texts, true_labels), 1):        AutoTokenizer,import json

        predicted_label = simple_classify(text)

        is_correct = predicted_label == true_label        AutoModelForSequenceClassification,

        

        print(f"{i}. Text: '{text}'")        TrainingArguments,from typing import List, Dict, Tuple, Optional

        print(f"   True: {true_label}")

        print(f"   Predicted: {predicted_label}")        Trainer,

        print(f"   Result: {'âœ“ Correct' if is_correct else 'âœ— Incorrect'}")

        print()        DataCollatorWithPadding,from dataclasses import dataclass

        

        if is_correct:    )

            correct += 1

        ä½œè€…: GenerativeAI-Starter-Kitæ–‡æœ¬åˆ†ç±»å¾®è°ƒç¤ºä¾‹ - é›¶é”™è¯¯ç‰ˆæœ¬æ–‡æœ¬åˆ†ç±»å¾®è°ƒç¤ºä¾‹ - é›¶é”™è¯¯ç‰ˆæœ¬

    accuracy = correct / total

    print(f"Final Results:")    from datasets import Dataset

    print(f"Accuracy: {accuracy:.1%} ({correct}/{total})")

    print("Demo completed successfully!")    import matplotlib.pyplot as plt# å¯é€‰ä¾èµ–æ£€æŸ¥



    DEPENDENCIES_AVAILABLE = True

if __name__ == "__main__":

    run_demo()except ImportError:try:"""

    print("Warning: Some dependencies not installed, running simplified version")

    DEPENDENCIES_AVAILABLE = False    import torch



    import numpy as npè¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºæ–‡æœ¬åˆ†ç±»çš„åŸºæœ¬æ¦‚å¿µå’Œæµç¨‹

@dataclass

class FineTuningConfig:    import pandas as pd

    """Fine-tuning configuration class"""

    model_name: str = "distilbert-base-uncased"    from sklearn.model_selection import train_test_splitfrom typing import List, Dict, Tuple

    num_labels: int = 2

    max_length: int = 512    from sklearn.metrics import accuracy_score, classification_report

    batch_size: int = 16

    learning_rate: float = 2e-5    ä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•é¿å…å¤æ‚çš„ä¾èµ–é—®é¢˜==================================================

    num_epochs: int = 3

    warmup_steps: int = 500    from transformers import (

    weight_decay: float = 0.01

    output_dir: str = "./fine_tuned_models"        AutoTokenizer,

    save_steps: int = 500

    eval_steps: int = 500        AutoModelForSequenceClassification,

    logging_steps: int = 100

        TrainingArguments,def create_sample_data() -> Tuple[List[str], List[str]]:



def create_sample_data() -> Tuple[List[str], List[str]]:        Trainer,

    """Create sample data for demonstration"""

    texts = [        DataCollatorWithPadding,    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""

        "I love this product! It's amazing.",

        "This is terrible, don't recommend it.",    )

        "The product is okay, nothing special.",

        "Great quality, worth buying!",        texts = [ä½œè€…: GenerativeAI-Starter-Kit

        "Completely useless, waste of money."

    ]    from datasets import Dataset

    

    labels = ["positive", "negative", "neutral", "positive", "negative"]    import matplotlib.pyplot as plt        "æˆ‘å–œæ¬¢è¿™ä¸ªäº§å“ï¼éå¸¸æ£’ã€‚",

    

    return texts, labels    DEPENDENCIES_AVAILABLE = True



except ImportError:        "è¿™ä¸œè¥¿å¾ˆç³Ÿç³•ï¼Œä¸æ¨èã€‚",è®¸å¯: MIT

def simple_classify(text: str) -> str:

    """Simple rule-based classifier"""    print("âš ï¸ éƒ¨åˆ†ä¾èµ–æœªå®‰è£…ï¼Œå°†è¿è¡Œç®€åŒ–ç‰ˆæœ¬")

    positive_words = ["love", "amazing", "great", "worth", "excellent"]

    negative_words = ["terrible", "useless", "waste", "bad", "awful"]    DEPENDENCIES_AVAILABLE = False        "äº§å“è¿˜å¯ä»¥ï¼Œä¸€èˆ¬èˆ¬ã€‚",

    

    text_lower = text.lower()

    pos_count = sum(1 for word in positive_words if word in text_lower)

    neg_count = sum(1 for word in negative_words if word in text_lower)        "è´¨é‡å¾ˆå¥½ï¼Œå€¼å¾—è´­ä¹°ï¼","""è¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»è¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»

    

    if pos_count > neg_count:@dataclass

        return "positive"

    elif neg_count > pos_count:class FineTuningConfig:        "å®Œå…¨æ²¡ç”¨ï¼Œæµªè´¹é’±ã€‚"

        return "negative"

    else:    """å¾®è°ƒé…ç½®ç±»"""

        return "neutral"

    model_name: str = "distilbert-base-uncased"    ]



def demo_classification():    num_labels: int = 2

    """Demonstrate classification process"""

    print("Text Classification Demo")    max_length: int = 512    

    print("=" * 30)

        batch_size: int = 16

    texts, labels = create_sample_data()

        learning_rate: float = 2e-5    labels = ["positive", "negative", "neutral", "positive", "negative"]import osä½¿ç”¨BERTç±»å‹çš„æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†ææˆ–è‡ªå®šä¹‰åˆ†ç±»ä»»åŠ¡ä½¿ç”¨BERTç±»å‹çš„æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†ææˆ–è‡ªå®šä¹‰åˆ†ç±»ä»»åŠ¡

    print(f"Data: {len(texts)} samples")

    print()    num_epochs: int = 3

    

    correct = 0    warmup_steps: int = 500    

    for text, true_label in zip(texts, labels):

        pred_label = simple_classify(text)    weight_decay: float = 0.01

        is_correct = pred_label == true_label

            output_dir: str = "./fine_tuned_models"    return texts, labelsimport json

        print(f"Text: '{text}'")

        print(f"True: {true_label} | Predicted: {pred_label} {'âœ“' if is_correct else 'âœ—'}")    save_steps: int = 500

        print()

            eval_steps: int = 500

        if is_correct:

            correct += 1    logging_steps: int = 100

    

    accuracy = correct / len(texts)from typing import List, Dict, Tuple, Optional

    print(f"Accuracy: {accuracy:.3f} ({correct}/{len(texts)})")

    print("Demo completed!")



def create_sample_data() -> Tuple[List[str], List[str]]:def simple_classify(text: str) -> str:

if DEPENDENCIES_AVAILABLE:

    class TextClassificationTrainer:    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""

        """Text classification fine-tuner"""

            texts = [    """ç®€å•çš„åŸºäºè§„åˆ™çš„åˆ†ç±»"""

        def __init__(self, config: Optional[FineTuningConfig] = None):

            self.config = config or FineTuningConfig()        "æˆ‘å–œæ¬¢è¿™ä¸ªäº§å“ï¼éå¸¸æ£’ã€‚",

            self.tokenizer = None

            self.model = None        "è¿™ä¸œè¥¿å¾ˆç³Ÿç³•ï¼Œä¸æ¨èã€‚",    positive_words = ["å–œæ¬¢", "æ£’", "å¥½", "æ¨è", "å€¼å¾—"]

            self.trainer = None

            self.label_to_id = {}        "äº§å“è¿˜å¯ä»¥ï¼Œä¸€èˆ¬èˆ¬ã€‚",

            self.id_to_label = {}

                "è´¨é‡å¾ˆå¥½ï¼Œå€¼å¾—è´­ä¹°ï¼",    negative_words = ["ç³Ÿç³•", "æ²¡ç”¨", "æµªè´¹", "ä¸æ¨è"]ä½œè€…: GenerativeAI-Starter-Kitä½œè€…: GenerativeAI-Starter-Kit

        def initialize(self):

            """Initialize tokenizer and model"""        "å®Œå…¨æ²¡ç”¨ï¼Œæµªè´¹é’±ã€‚"

            print("Initializing fine-tuning setup...")

                ]    

            # Load tokenizer

            print(f"Loading tokenizer: {self.config.model_name}")    

            self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)

                labels = ["positive", "negative", "neutral", "positive", "negative"]    pos_count = sum(1 for word in positive_words if word in text)def create_sample_data() -> Tuple[List[str], List[str]]:

            # Load model

            print(f"Loading model: {self.config.model_name}")    

            self.model = AutoModelForSequenceClassification.from_pretrained(

                self.config.model_name,     return texts, labels    neg_count = sum(1 for word in negative_words if word in text)

                num_labels=self.config.num_labels

            )

            

            print("Initialization complete")        """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""è®¸å¯: MITè®¸å¯: MIT

        

        def predict(self, texts: List[str]) -> List[Dict]:def simple_classify(text: str) -> str:

            """Make predictions on new texts"""

            if not self.model or not self.tokenizer:    """ç®€å•çš„åŸºäºè§„åˆ™çš„åˆ†ç±»"""    if pos_count > neg_count:

                raise ValueError("Model not initialized")

                positive_words = ["å–œæ¬¢", "æ£’", "å¥½", "æ¨è", "å€¼å¾—"]

            predictions = []

                negative_words = ["ç³Ÿç³•", "æ²¡ç”¨", "æµªè´¹", "ä¸æ¨è"]        return "positive"    texts = [

            for text in texts:

                # Tokenize    

                inputs = self.tokenizer(

                    text,    pos_count = sum(1 for word in positive_words if word in text)    elif neg_count > pos_count:

                    return_tensors="pt",

                    truncation=True,    neg_count = sum(1 for word in negative_words if word in text)

                    padding=True,

                    max_length=self.config.max_length,            return "negative"        "æˆ‘å–œæ¬¢è¿™ä¸ªäº§å“ï¼éå¸¸æ£’ï¼Œæ•ˆæœå¾ˆå¥½ã€‚",""""""

                )

                    if pos_count > neg_count:

                # Predict

                with torch.no_grad():        return "positive"    else:

                    outputs = self.model(**inputs)

                    logits = outputs.logits    elif neg_count > pos_count:

                    probabilities = torch.nn.functional.softmax(logits, dim=-1)

                    predicted_class = torch.argmax(logits, dim=-1).item()        return "negative"        return "neutral"        "è¿™æ˜¯æˆ‘ä¹°è¿‡æœ€ç³Ÿç³•çš„ä¸œè¥¿ã€‚å®Œå…¨æ²¡ç”¨ã€‚",

                

                # Format result    else:

                result = {

                    "text": text,        return "neutral"

                    "predicted_label": self.id_to_label[predicted_class],

                    "confidence": probabilities[0][predicted_class].item()

                }

                        "äº§å“è¿˜å¯ä»¥ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«ä½†èƒ½ç”¨ã€‚",

                predictions.append(result)

            def demo_classification():

            return predictions

    """æ¼”ç¤ºåˆ†ç±»è¿‡ç¨‹"""def demo_classification():



def main():    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»æ¼”ç¤º")

    """Main function"""

    if DEPENDENCIES_AVAILABLE:    print("=" * 30)    """æ¼”ç¤ºåˆ†ç±»è¿‡ç¨‹"""        "è´¨é‡å¾ˆå¥½ï¼Œå®¢æœä¹Ÿä¸é”™ã€‚å¼ºçƒˆæ¨èï¼",

        print("Full version available - includes deep learning features")

        demo_classification()    

        print("\nTip: Use TextClassificationTrainer for advanced fine-tuning")

    else:    texts, labels = create_sample_data()    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»æ¼”ç¤º")

        print("Simplified version - rule-based classification")

        demo_classification()    

        print("\nInstall dependencies for full functionality:")

        print("pip install torch transformers datasets pandas scikit-learn")    print(f"ğŸ“Š æ•°æ®: {len(texts)} ä¸ªæ ·æœ¬")    print("=" * 30)        "ç³Ÿç³•çš„ä½“éªŒã€‚äº§å“ç”¨äº†ä¸€å¤©å°±åäº†ã€‚",import osimport os



    print()

if __name__ == "__main__":

    main()        

    correct = 0

    for text, true_label in zip(texts, labels):    texts, labels = create_sample_data()        "æ€§ä»·æ¯”ä¸é”™ã€‚ä¼šå†æ¬¡è´­ä¹°ã€‚",

        pred_label = simple_classify(text)

        is_correct = pred_label == true_label    

        

        print(f"æ–‡æœ¬: '{text}'")    print(f"ğŸ“Š æ•°æ®: {len(texts)} ä¸ªæ ·æœ¬")        "ä¸å€¼è¿™ä¸ªä»·æ ¼ã€‚å¾ˆå¤±æœ›ã€‚",import jsonimport json

        print(f"çœŸå®: {true_label} | é¢„æµ‹: {pred_label} {'âœ“' if is_correct else 'âœ—'}")

        print()    print()

        

        if is_correct:            "è´¨é‡ä¼˜ç§€ï¼Œå‘è´§å¾ˆå¿«ã€‚",

            correct += 1

        correct = 0

    accuracy = correct / len(texts)

    print(f"ğŸ“ˆ å‡†ç¡®ç‡: {accuracy:.3f} ({correct}/{len(texts)})")    for text, true_label in zip(texts, labels):        "äº§å“ä¸é”™ä½†è¿˜æœ‰æ”¹è¿›ç©ºé—´ã€‚",from typing import List, Dict, Tuple, Optionalfrom typing import List, Dict, Tuple, Optional

    print("âœ… æ¼”ç¤ºå®Œæˆ!")

        pred_label = simple_classify(text)



if DEPENDENCIES_AVAILABLE:        is_correct = pred_label == true_label        "å¤ªæ£’äº†ï¼è¶…å‡ºäº†æˆ‘çš„æœŸæœ›ã€‚"

    class TextClassificationTrainer:

        """æ–‡æœ¬åˆ†ç±»å¾®è°ƒå™¨"""        

        

        def __init__(self, config: Optional[FineTuningConfig] = None):        print(f"æ–‡æœ¬: '{text}'")    ]from dataclasses import dataclassfrom dataclasses import dataclass

            self.config = config or FineTuningConfig()

            self.tokenizer = None        print(f"çœŸå®: {true_label} | é¢„æµ‹: {pred_label} {'âœ“' if is_correct else 'âœ—'}")

            self.model = None

            self.trainer = None        print()

            self.label_to_id = {}

            self.id_to_label = {}        

        

        def initialize(self):        if is_correct:    labels = [

            """åˆå§‹åŒ–åˆ†è¯å™¨å’Œæ¨¡å‹"""

            print("ğŸš€ åˆå§‹åŒ–å¾®è°ƒè®¾ç½®...")            correct += 1

            

            # åŠ è½½åˆ†è¯å™¨            "positive",

            print(f"ğŸ“– åŠ è½½åˆ†è¯å™¨: {self.config.model_name}")

            self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)    accuracy = correct / len(texts)

            

            # åŠ è½½æ¨¡å‹    print(f"ğŸ“ˆ å‡†ç¡®ç‡: {accuracy:.3f} ({correct}/{len(texts)})")        "negative", # æ³¨æ„ï¼šä»¥ä¸‹ä¾èµ–éœ€è¦å•ç‹¬å®‰è£…# æ³¨æ„ï¼šä»¥ä¸‹ä¾èµ–éœ€è¦å•ç‹¬å®‰è£…

            print(f"ğŸ§  åŠ è½½æ¨¡å‹: {self.config.model_name}")

            self.model = AutoModelForSequenceClassification.from_pretrained(    print("âœ… æ¼”ç¤ºå®Œæˆ!")

                self.config.model_name, 

                num_labels=self.config.num_labels        "neutral",

            )

            

            print("âœ… åˆå§‹åŒ–å®Œæˆ")

        if __name__ == "__main__":        "positive",# pip install torch transformers datasets pandas scikit-learn matplotlib seaborn# pip install torch transformers datasets pandas scikit-learn matplotlib seaborn

        def predict(self, texts: List[str]) -> List[Dict]:

            """å¯¹æ–°æ–‡æœ¬è¿›è¡Œé¢„æµ‹"""    demo_classification()

            if not self.model or not self.tokenizer:        "negative",

                raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–")

                    "positive",

            predictions = []

                    "negative",

            for text in texts:

                # åˆ†è¯        "positive",try:try:

                inputs = self.tokenizer(

                    text,        "neutral", 

                    return_tensors="pt",

                    truncation=True,        "positive"    import torch    import torch

                    padding=True,

                    max_length=self.config.max_length,    ]

                )

                    import numpy as np    import numpy as np

                # é¢„æµ‹

                with torch.no_grad():    return texts, labels

                    outputs = self.model(**inputs)

                    logits = outputs.logits    import pandas as pd    import pandas as pd

                    probabilities = torch.nn.functional.softmax(logits, dim=-1)

                    predicted_class = torch.argmax(logits, dim=-1).item()

                

                # æ ¼å¼åŒ–ç»“æœdef analyze_data(texts: List[str], labels: List[str]) -> Dict:    from sklearn.model_selection import train_test_split    from sklearn.model_selection import train_test_split

                result = {

                    "text": text,    """åˆ†ææ•°æ®çš„åŸºæœ¬ç»Ÿè®¡"""

                    "predicted_label": self.id_to_label[predicted_class],

                    "confidence": probabilities[0][predicted_class].item()    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ    from sklearn.metrics import accuracy_score, classification_report    from sklearn.metrics import accuracy_score, classification_report

                }

                    label_counts = {}

                predictions.append(result)

                for label in labels:        

            return predictions

        label_counts[label] = label_counts.get(label, 0) + 1



def main():        from transformers import (    from transformers import (

    """ä¸»å‡½æ•°"""

    if DEPENDENCIES_AVAILABLE:    # ç»Ÿè®¡æ–‡æœ¬é•¿åº¦

        print("ğŸš€ å®Œæ•´ç‰ˆæœ¬å¯ç”¨ - åŒ…å«æ·±åº¦å­¦ä¹ åŠŸèƒ½")

        demo_classification()    text_lengths = [len(text) for text in texts]        AutoTokenizer,        AutoTokenizer,

        print("\nğŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨ TextClassificationTrainer è¿›è¡Œé«˜çº§å¾®è°ƒ")

    else:    avg_length = sum(text_lengths) / len(text_lengths)

        print("ğŸ“ ç®€åŒ–ç‰ˆæœ¬ - åŸºäºè§„åˆ™çš„åˆ†ç±»")

        demo_classification()            AutoModelForSequenceClassification,        AutoModelForSequenceClassification,

        print("\nğŸ’¡ å®‰è£…ä¾èµ–ä»¥ä½¿ç”¨å®Œæ•´åŠŸèƒ½:")

        print("pip install torch transformers datasets pandas scikit-learn")    return {



        "total_samples": len(texts),        TrainingArguments,        TrainingArguments,

if __name__ == "__main__":

    main()        "label_distribution": label_counts,

        "average_text_length": avg_length,        Trainer,        Trainer,

        "min_length": min(text_lengths),

        "max_length": max(text_lengths)        DataCollatorWithPadding,        DataCollatorWithPadding,

    }

    )    )



def simple_word_features(text: str) -> Dict[str, int]:        

    """æå–ç®€å•çš„è¯æ±‡ç‰¹å¾"""

    # æƒ…æ„Ÿè¯æ±‡    from datasets import Dataset    from datasets import Dataset

    positive_words = ["å–œæ¬¢", "æ£’", "å¥½", "æ¨è", "ä¼˜ç§€", "å¿«", "æ»¡æ„", "ä¸é”™"]

    negative_words = ["ç³Ÿç³•", "æ²¡ç”¨", "å¤±æœ›", "å·®", "å", "æµªè´¹"]    import matplotlib.pyplot as plt    import matplotlib.pyplot as plt

    neutral_words = ["è¿˜å¯ä»¥", "è¿˜è¡Œ", "ä¸€èˆ¬", "æ™®é€š"]

        DEPENDENCIES_AVAILABLE = True    DEPENDENCIES_AVAILABLE = True

    text_lower = text.lower()

    except ImportError as e:except ImportError as e:

    features = {

        "positive_count": sum(1 for word in positive_words if word in text_lower),    print(f"âš ï¸ ç¼ºå°‘ä¾èµ–åŒ…: {e}")    print(f"âš ï¸ ç¼ºå°‘ä¾èµ–åŒ…: {e}")

        "negative_count": sum(1 for word in negative_words if word in text_lower),

        "neutral_count": sum(1 for word in neutral_words if word in text_lower),    print("è¯·è¿è¡Œ: pip install torch transformers datasets pandas scikit-learn matplotlib seaborn")    print("è¯·è¿è¡Œ: pip install torch transformers datasets pandas scikit-learn matplotlib seaborn")

        "text_length": len(text),

        "exclamation_count": text.count("!"),    DEPENDENCIES_AVAILABLE = False    DEPENDENCIES_AVAILABLE = False

        "question_count": text.count("?")

    }

    

    return features



@dataclass@dataclass

def simple_classify(text: str) -> Dict[str, any]:

    """ç®€å•çš„åŸºäºè§„åˆ™çš„åˆ†ç±»å™¨"""class FineTuningConfig:class FineTuningConfig:

    features = simple_word_features(text)

        """å¾®è°ƒé…ç½®ç±»"""    """å¾®è°ƒé…ç½®ç±»"""

    # ç®€å•çš„åˆ†ç±»é€»è¾‘

    positive_score = features["positive_count"] + features["exclamation_count"] * 0.5    model_name: str = "distilbert-base-uncased"    model_name: str = "distilbert-base-uncased"

    negative_score = features["negative_count"]

    neutral_score = features["neutral_count"]    num_labels: int = 2    num_labels: int = 2

    

    scores = {    max_length: int = 512    max_length: int = 512

        "positive": positive_score,

        "negative": negative_score,    batch_size: int = 16    batch_size: int = 16

        "neutral": neutral_score

    }    learning_rate: float = 2e-5    learning_rate: float = 2e-5

    

    # é€‰æ‹©æœ€é«˜åˆ†çš„æ ‡ç­¾    num_epochs: int = 3    num_epochs: int = 3

    predicted_label = max(scores, key=scores.get)

        warmup_steps: int = 500    warmup_steps: int = 500

    # å¦‚æœæ‰€æœ‰åˆ†æ•°éƒ½æ˜¯0ï¼Œé»˜è®¤ä¸ºneutral

    if all(score == 0 for score in scores.values()):    weight_decay: float = 0.01    weight_decay: float = 0.01

        predicted_label = "neutral"

        output_dir: str = "./fine_tuned_models"    output_dir: str = "./fine_tuned_models"

    return {

        "text": text,    save_steps: int = 500    save_steps: int = 500

        "predicted_label": predicted_label,

        "scores": scores,    eval_steps: int = 500    eval_steps: int = 500

        "features": features

    }    logging_steps: int = 100    logging_steps: int = 100





def evaluate_simple_classifier(texts: List[str], true_labels: List[str]) -> Dict:

    """è¯„ä¼°ç®€å•åˆ†ç±»å™¨çš„æ€§èƒ½"""

    predictions = []

    correct = 0class TextClassificationTrainer:class TextClassificationTrainer:

    

    for text, true_label in zip(texts, true_labels):    """æ–‡æœ¬åˆ†ç±»å¾®è°ƒå™¨"""    """æ–‡æœ¬åˆ†ç±»å¾®è°ƒå™¨"""

        result = simple_classify(text)

        predictions.append(result)        

        

        if result["predicted_label"] == true_label:    def __init__(self, config: Optional[FineTuningConfig] = None):    def __init__(self, config: Optional[FineTuningConfig] = None):

            correct += 1

            self.config = config or FineTuningConfig()        self.config = config or FineTuningConfig()

    accuracy = correct / len(texts)

            self.tokenizer = None        self.tokenizer = None

    return {

        "accuracy": accuracy,        self.model = None        self.model = None

        "correct_predictions": correct,

        "total_predictions": len(texts),        self.trainer = None        self.trainer = None

        "predictions": predictions

    }        self.label_to_id = {}        self.label_to_id = {}



        self.id_to_label = {}        self.id_to_label = {}

def demo_text_classification():

    """æ¼”ç¤ºæ–‡æœ¬åˆ†ç±»è¿‡ç¨‹"""        

    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»æ¼”ç¤º")

    print("=" * 40)    def check_dependencies(self) -> bool:    def check_dependencies(self) -> bool:

    

    # åˆ›å»ºç¤ºä¾‹æ•°æ®        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨"""        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨"""

    texts, labels = create_sample_data()

    print(f"ğŸ“Š åˆ›å»ºäº† {len(texts)} ä¸ªç¤ºä¾‹æ–‡æœ¬")        return DEPENDENCIES_AVAILABLE        return DEPENDENCIES_AVAILABLE

    

    # åˆ†ææ•°æ®        

    stats = analyze_data(texts, labels)

    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")    def initialize(self):    def initialize(self):

    print(f"  æ€»æ ·æœ¬æ•°: {stats['total_samples']}")

    print(f"  å¹³å‡æ–‡æœ¬é•¿åº¦: {stats['average_text_length']:.1f} å­—ç¬¦")        """åˆå§‹åŒ–åˆ†è¯å™¨å’Œæ¨¡å‹"""        """åˆå§‹åŒ–åˆ†è¯å™¨å’Œæ¨¡å‹"""

    print(f"  æ ‡ç­¾åˆ†å¸ƒ:")

    for label, count in stats['label_distribution'].items():        if not self.check_dependencies():        if not self.check_dependencies():

        print(f"    {label}: {count} ä¸ª")

                raise ImportError("ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…ï¼Œè¯·å…ˆå®‰è£…")            raise ImportError("ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…ï¼Œè¯·å…ˆå®‰è£…")

    # æ¼”ç¤ºç‰¹å¾æå–

    print(f"\nğŸ” ç‰¹å¾æå–æ¼”ç¤º:")                

    example_text = texts[0]

    features = simple_word_features(example_text)        print("ğŸš€ åˆå§‹åŒ–å¾®è°ƒè®¾ç½®...")        print("ğŸš€ åˆå§‹åŒ–å¾®è°ƒè®¾ç½®...")

    print(f"  ç¤ºä¾‹æ–‡æœ¬: '{example_text}'")

    print(f"  æå–çš„ç‰¹å¾: {features}")                

    

    # æ¼”ç¤ºåˆ†ç±»        # åŠ è½½åˆ†è¯å™¨        # åŠ è½½åˆ†è¯å™¨

    print(f"\nğŸ”® åˆ†ç±»æ¼”ç¤º:")

    for i in range(min(3, len(texts))):        print(f"ğŸ“– åŠ è½½åˆ†è¯å™¨: {self.config.model_name}")        print(f"ğŸ“– åŠ è½½åˆ†è¯å™¨: {self.config.model_name}")

        result = simple_classify(texts[i])

        print(f"  æ–‡æœ¬: '{result['text']}'")        self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)        self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)

        print(f"  çœŸå®æ ‡ç­¾: {labels[i]}")

        print(f"  é¢„æµ‹æ ‡ç­¾: {result['predicted_label']}")                

        print(f"  åˆ†æ•°: {result['scores']}")

        print()        # åŠ è½½æ¨¡å‹        # åŠ è½½æ¨¡å‹

    

    # è¯„ä¼°æ€§èƒ½        print(f"ğŸ§  åŠ è½½æ¨¡å‹: {self.config.model_name}")        print(f"ğŸ§  åŠ è½½æ¨¡å‹: {self.config.model_name}")

    print(f"ğŸ“Š æ•´ä½“æ€§èƒ½è¯„ä¼°:")

    evaluation = evaluate_simple_classifier(texts, labels)        self.model = AutoModelForSequenceClassification.from_pretrained(        self.model = AutoModelForSequenceClassification.from_pretrained(

    print(f"  å‡†ç¡®ç‡: {evaluation['accuracy']:.3f}")

    print(f"  æ­£ç¡®é¢„æµ‹: {evaluation['correct_predictions']}/{evaluation['total_predictions']}")            self.config.model_name,             self.config.model_name, 

    

    print(f"\nâœ… æ¼”ç¤ºå®Œæˆ!")            num_labels=self.config.num_labels            num_labels=self.config.num_labels

    print(f"ğŸ’¡ è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹")

    print(f"   å®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹")        )        )



                

def show_ml_pipeline_info():

    """æ˜¾ç¤ºæœºå™¨å­¦ä¹ æµæ°´çº¿ä¿¡æ¯"""        print("âœ… åˆå§‹åŒ–å®Œæˆ")        print("âœ… åˆå§‹åŒ–å®Œæˆ")

    print(f"\nğŸš€ æœºå™¨å­¦ä¹ æ–‡æœ¬åˆ†ç±»æµæ°´çº¿:")

    print(f"=" * 50)        

    

    pipeline_steps = [    def prepare_data(self, texts: List[str], labels: List[str], test_size: float = 0.2) -> Tuple[Dataset, Dataset]:    def prepare_data(self, texts: List[str], labels: List[str], test_size: float = 0.2) -> Tuple[Dataset, Dataset]:

        ("1. æ•°æ®æ”¶é›†", "æ”¶é›†å¸¦æ ‡ç­¾çš„æ–‡æœ¬æ•°æ®"),

        ("2. æ•°æ®é¢„å¤„ç†", "æ¸…æ´—ã€åˆ†è¯ã€å»é™¤åœç”¨è¯"),        """å‡†å¤‡å’Œåˆ†è¯æ•°æ®ç”¨äºè®­ç»ƒ"""        """å‡†å¤‡å’Œåˆ†è¯æ•°æ®ç”¨äºè®­ç»ƒ"""

        ("3. ç‰¹å¾å·¥ç¨‹", "TF-IDFã€è¯åµŒå…¥ã€BERTç­‰"),

        ("4. æ¨¡å‹é€‰æ‹©", "æœ´ç´ è´å¶æ–¯ã€SVMã€ç¥ç»ç½‘ç»œ"),        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")

        ("5. æ¨¡å‹è®­ç»ƒ", "ä½¿ç”¨è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹"),

        ("6. æ¨¡å‹è¯„ä¼°", "ä½¿ç”¨éªŒè¯é›†è¯„ä¼°æ€§èƒ½"),                

        ("7. è¶…å‚æ•°è°ƒä¼˜", "ç½‘æ ¼æœç´¢ã€éšæœºæœç´¢"),

        ("8. æ¨¡å‹éƒ¨ç½²", "å°†æ¨¡å‹éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")        # åˆ›å»ºæ ‡ç­¾æ˜ å°„        # åˆ›å»ºæ ‡ç­¾æ˜ å°„

    ]

            unique_labels = list(set(labels))        unique_labels = list(set(labels))

    for step, description in pipeline_steps:

        print(f"{step}: {description}")        self.label_to_id = {label: idx for idx, label in enumerate(unique_labels)}        self.label_to_id = {label: idx for idx, label in enumerate(unique_labels)}

    

    print(f"\nğŸ”§ å¸¸ç”¨å·¥å…·å’Œåº“:")        self.id_to_label = {idx: label for label, idx in self.label_to_id.items()}        self.id_to_label = {idx: label for label, idx in self.label_to_id.items()}

    tools = [

        "scikit-learn: ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•",                

        "transformers: é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹",

        "torch/tensorflow: æ·±åº¦å­¦ä¹ æ¡†æ¶",        print(f"æ ‡ç­¾: {self.label_to_id}")        print(f"æ ‡ç­¾: {self.label_to_id}")

        "pandas: æ•°æ®å¤„ç†",

        "nltk/spacy: è‡ªç„¶è¯­è¨€å¤„ç†"                

    ]

            # å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸ºæ•°å­—        # è½¬æ¢å­—ç¬¦ä¸²æ ‡ç­¾ä¸ºæ•°å­—

    for tool in tools:

        print(f"  â€¢ {tool}")        numeric_labels = [self.label_to_id[label] for label in labels]        numeric_labels = [self.label_to_id[label] for label in labels]



                

if __name__ == "__main__":

    demo_text_classification()        # åˆ†å‰²æ•°æ®        # åˆ†å‰²æ•°æ®

    show_ml_pipeline_info()
        train_texts, val_texts, train_labels, val_labels = train_test_split(        train_texts, val_texts, train_labels, val_labels = train_test_split(

            texts, numeric_labels, test_size=test_size, random_state=42, stratify=numeric_labels            texts, numeric_labels, test_size=test_size, random_state=42, stratify=numeric_labels

        )        )

                

        print(f"è®­ç»ƒæ ·æœ¬: {len(train_texts)}")        print(f"è®­ç»ƒæ ·æœ¬: {len(train_texts)}")

        print(f"éªŒè¯æ ·æœ¬: {len(val_texts)}")        print(f"éªŒè¯æ ·æœ¬: {len(val_texts)}")

                

        # åˆ†è¯å‡½æ•°        # åˆ†è¯å‡½æ•°

        def tokenize_function(examples):        def tokenize_function(examples):

            return self.tokenizer(            return self.tokenizer(

                examples["text"],                examples["text"],

                truncation=True,                truncation=True,

                padding=True,                padding=True,

                max_length=self.config.max_length,                max_length=self.config.max_length,

            )            )

                

        # åˆ›å»ºæ•°æ®é›†        # åˆ›å»ºæ•°æ®é›†

        train_dataset = Dataset.from_dict({"text": train_texts, "labels": train_labels})        train_dataset = Dataset.from_dict({"text": train_texts, "labels": train_labels})

        val_dataset = Dataset.from_dict({"text": val_texts, "labels": val_labels})        val_dataset = Dataset.from_dict({"text": val_texts, "labels": val_labels})

                

        # åˆ†è¯        # åˆ†è¯

        train_dataset = train_dataset.map(tokenize_function, batched=True)        train_dataset = train_dataset.map(tokenize_function, batched=True)

        val_dataset = val_dataset.map(tokenize_function, batched=True)        val_dataset = val_dataset.map(tokenize_function, batched=True)

                

        return train_dataset, val_dataset        return train_dataset, val_dataset

        

    def compute_metrics(self, eval_pred):    def compute_metrics(self, eval_pred):

        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""

        predictions, labels = eval_pred        predictions, labels = eval_pred

        predictions = np.argmax(predictions, axis=1)        predictions = np.argmax(predictions, axis=1)

        accuracy = accuracy_score(labels, predictions)        accuracy = accuracy_score(labels, predictions)

        return {"accuracy": accuracy}        return {"accuracy": accuracy}

        

    def train(self, train_dataset: Dataset, val_dataset: Dataset):    def train(self, train_dataset: Dataset, val_dataset: Dataset):

        """è®­ç»ƒæ¨¡å‹"""        """è®­ç»ƒæ¨¡å‹"""

        print("ğŸ‹ï¸ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")        print("ğŸ‹ï¸ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

                

        # è®­ç»ƒå‚æ•°        # è®­ç»ƒå‚æ•°

        training_args = TrainingArguments(        training_args = TrainingArguments(

            output_dir=self.config.output_dir,            output_dir=self.config.output_dir,

            num_train_epochs=self.config.num_epochs,            num_train_epochs=self.config.num_epochs,

            per_device_train_batch_size=self.config.batch_size,            per_device_train_batch_size=self.config.batch_size,

            per_device_eval_batch_size=self.config.batch_size,            per_device_eval_batch_size=self.config.batch_size,

            warmup_steps=self.config.warmup_steps,            warmup_steps=self.config.warmup_steps,

            weight_decay=self.config.weight_decay,            weight_decay=self.config.weight_decay,

            logging_dir=f"{self.config.output_dir}/logs",            logging_dir=f"{self.config.output_dir}/logs",

            logging_steps=self.config.logging_steps,            logging_steps=self.config.logging_steps,

            evaluation_strategy="steps",            evaluation_strategy="steps",

            eval_steps=self.config.eval_steps,            eval_steps=self.config.eval_steps,

            save_steps=self.config.save_steps,            save_steps=self.config.save_steps,

            load_best_model_at_end=True,            load_best_model_at_end=True,

            metric_for_best_model="accuracy",            metric_for_best_model="accuracy",

            greater_is_better=True,            greater_is_better=True,

            report_to="none",  # ç¦ç”¨wandb/tensorboard            report_to="none",

        )        )

                

        # æ•°æ®æ•´ç†å™¨        # æ•°æ®æ•´ç†å™¨

        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)

                

        # åˆå§‹åŒ–è®­ç»ƒå™¨        # åˆå§‹åŒ–è®­ç»ƒå™¨

        self.trainer = Trainer(        self.trainer = Trainer(

            model=self.model,            model=self.model,

            args=training_args,            args=training_args,

            train_dataset=train_dataset,            train_dataset=train_dataset,

            eval_dataset=val_dataset,            eval_dataset=val_dataset,

            tokenizer=self.tokenizer,            tokenizer=self.tokenizer,

            data_collator=data_collator,            data_collator=data_collator,

            compute_metrics=self.compute_metrics,            compute_metrics=self.compute_metrics,

        )        )

                

        # è®­ç»ƒ        # è®­ç»ƒ

        train_result = self.trainer.train()        train_result = self.trainer.train()

                

        # ä¿å­˜æ¨¡å‹        # ä¿å­˜æ¨¡å‹

        self.trainer.save_model()        self.trainer.save_model()

                

        print("âœ… è®­ç»ƒå®Œæˆ!")        print("âœ… è®­ç»ƒå®Œæˆ!")

        print(f"è®­ç»ƒæŸå¤±: {train_result.training_loss:.4f}")        print(f"è®­ç»ƒæŸå¤±: {train_result.training_loss:.4f}")

                

        return train_result        return train_result

        

    def evaluate(self, test_dataset: Dataset) -> Dict:    def predict(self, texts: List[str]) -> List[Dict]:

        """è¯„ä¼°æ¨¡å‹"""        """å¯¹æ–°æ–‡æœ¬è¿›è¡Œé¢„æµ‹"""

        if not self.trainer:        if not self.model or not self.tokenizer:

            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒã€‚è¯·å…ˆè°ƒç”¨ train() æ–¹æ³•ã€‚")            raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize()")

                

        print("ğŸ“Š è¯„ä¼°æ¨¡å‹...")        predictions = []

        eval_result = self.trainer.evaluate(test_dataset)        

                for text in texts:

        print(f"è¯„ä¼°å‡†ç¡®ç‡: {eval_result['eval_accuracy']:.4f}")            # åˆ†è¯

                    inputs = self.tokenizer(

        return eval_result                text,

                    return_tensors="pt",

    def predict(self, texts: List[str]) -> List[Dict]:                truncation=True,

        """å¯¹æ–°æ–‡æœ¬è¿›è¡Œé¢„æµ‹"""                padding=True,

        if not self.model or not self.tokenizer:                max_length=self.config.max_length,

            raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ã€‚è¯·å…ˆè°ƒç”¨ initialize() æ–¹æ³•ã€‚")            )

                    

        predictions = []            # é¢„æµ‹

                    with torch.no_grad():

        for text in texts:                outputs = self.model(**inputs)

            # åˆ†è¯                logits = outputs.logits

            inputs = self.tokenizer(                probabilities = torch.nn.functional.softmax(logits, dim=-1)

                text,                predicted_class = torch.argmax(logits, dim=-1).item()

                return_tensors="pt",            

                truncation=True,            # æ ¼å¼åŒ–ç»“æœ

                padding=True,            result = {

                max_length=self.config.max_length,                "text": text,

            )                "predicted_label": self.id_to_label[predicted_class],

                            "confidence": probabilities[0][predicted_class].item(),

            # é¢„æµ‹                "all_probabilities": {

            with torch.no_grad():                    self.id_to_label[i]: prob.item()

                outputs = self.model(**inputs)                    for i, prob in enumerate(probabilities[0])

                logits = outputs.logits                },

                probabilities = torch.nn.functional.softmax(logits, dim=-1)            }

                predicted_class = torch.argmax(logits, dim=-1).item()            

                        predictions.append(result)

            # æ ¼å¼åŒ–ç»“æœ        

            result = {        return predictions

                "text": text,

                "predicted_label": self.id_to_label[predicted_class],

                "confidence": probabilities[0][predicted_class].item(),def create_sample_data() -> Tuple[List[str], List[str]]:

                "all_probabilities": {    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""

                    self.id_to_label[i]: prob.item()    texts = [

                    for i, prob in enumerate(probabilities[0])        "æˆ‘å–œæ¬¢è¿™ä¸ªäº§å“! å®ƒå¾ˆæ£’å¹¶ä¸”å·¥ä½œå®Œç¾ã€‚",

                },        "è¿™æ˜¯æˆ‘ä¹°è¿‡æœ€ç³Ÿç³•çš„ä¸œè¥¿ã€‚å®Œå…¨æ²¡ç”¨ã€‚",

            }        "äº§å“è¿˜å¯ä»¥ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„ä½†èƒ½å®Œæˆå·¥ä½œã€‚",

                    "ä¼˜ç§€çš„è´¨é‡å’Œå¾ˆæ£’çš„å®¢æˆ·æœåŠ¡ã€‚å¼ºçƒˆæ¨è!",

            predictions.append(result)        "ç³Ÿç³•çš„ä½“éªŒã€‚äº§å“ä¸€å¤©å°±åäº†ã€‚",

                "ç‰©æœ‰æ‰€å€¼ã€‚ä¼šå†æ¬¡è´­ä¹°ã€‚",

        return predictions        "ä¸å€¼è¿™ä¸ªä»·æ ¼ã€‚éå¸¸å¤±æœ›ã€‚",

            "å‡ºè‰²çš„æ„å»ºè´¨é‡å’Œå¿«é€Ÿå‘è´§ã€‚",

    def save_model(self, path: str):        "äº§å“ä¸é”™ä½†å¯ä»¥æ›´å¥½ã€‚",

        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""        "æ°å‡ºçš„ï¼å®Œå…¨è¶…å‡ºæˆ‘çš„æœŸæœ›ã€‚"

        if not self.model or not self.tokenizer:    ]

            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒã€‚")    

            labels = [

        os.makedirs(path, exist_ok=True)        "positive", "negative", "neutral", "positive", "negative",

                "positive", "negative", "positive", "neutral", "positive"

        # ä¿å­˜æ¨¡å‹å’Œåˆ†è¯å™¨    ]

        self.model.save_pretrained(path)    

        self.tokenizer.save_pretrained(path)    return texts, labels

        

        # ä¿å­˜æ ‡ç­¾æ˜ å°„

        with open(os.path.join(path, "label_mappings.json"), "w") as f:def demo_fine_tuning():

            json.dump(    """æ¼”ç¤ºå¾®è°ƒè¿‡ç¨‹"""

                {"label_to_id": self.label_to_id, "id_to_label": self.id_to_label},    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»å¾®è°ƒæ¼”ç¤º")

                f,    print("=" * 50)

                indent=2,    

            )    # æ£€æŸ¥ä¾èµ–

            if not DEPENDENCIES_AVAILABLE:

        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ° {path}")        print("âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…")

            print("è¯·è¿è¡Œ: pip install torch transformers datasets pandas scikit-learn matplotlib")

    def load_model(self, path: str):        print("\nğŸ’¡ ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬æ¼”ç¤ºä»£æ›¿:")

        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""        print("python examples/fine-tuning/text_classification_demo.py")

        print(f"ğŸ“– ä» {path} åŠ è½½æ¨¡å‹")        return

            

        # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨    # åˆ›å»ºç¤ºä¾‹æ•°æ®

        self.model = AutoModelForSequenceClassification.from_pretrained(path)    texts, labels = create_sample_data()

        self.tokenizer = AutoTokenizer.from_pretrained(path)    print(f"ğŸ“Š åˆ›å»ºäº† {len(texts)} ä¸ªç¤ºä¾‹æ–‡æœ¬ï¼Œ{len(set(labels))} ä¸ªç±»åˆ«")

            

        # åŠ è½½æ ‡ç­¾æ˜ å°„    # åˆå§‹åŒ–è®­ç»ƒå™¨

        with open(os.path.join(path, "label_mappings.json"), "r") as f:    config = FineTuningConfig(

            mappings = json.load(f)        num_labels=len(set(labels)),

            self.label_to_id = mappings["label_to_id"]        num_epochs=2,  # æ¼”ç¤ºç”¨å‡å°‘

            self.id_to_label = {int(k): v for k, v in mappings["id_to_label"].items()}        batch_size=8,  # æ¼”ç¤ºç”¨å‡å°‘

            )

        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")    

    trainer = TextClassificationTrainer(config)

    

def create_sample_data() -> Tuple[List[str], List[str]]:    try:

    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""        trainer.initialize()

    texts = [        

        "æˆ‘å–œæ¬¢è¿™ä¸ªäº§å“ï¼éå¸¸æ£’ï¼Œæ•ˆæœå¾ˆå¥½ã€‚",        # å‡†å¤‡æ•°æ®

        "è¿™æ˜¯æˆ‘ä¹°è¿‡æœ€ç³Ÿç³•çš„ä¸œè¥¿ã€‚å®Œå…¨æ²¡ç”¨ã€‚",        train_dataset, val_dataset = trainer.prepare_data(texts, labels)

        "äº§å“è¿˜å¯ä»¥ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«ä½†èƒ½ç”¨ã€‚",        

        "è´¨é‡å¾ˆå¥½ï¼Œå®¢æœä¹Ÿä¸é”™ã€‚å¼ºçƒˆæ¨èï¼",        # è®­ç»ƒæ¨¡å‹

        "ç³Ÿç³•çš„ä½“éªŒã€‚äº§å“ç”¨äº†ä¸€å¤©å°±åäº†ã€‚",        print("\nğŸ‹ï¸ è®­ç»ƒæ¨¡å‹ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")

        "æ€§ä»·æ¯”ä¸é”™ã€‚ä¼šå†æ¬¡è´­ä¹°ã€‚",        train_result = trainer.train(train_dataset, val_dataset)

        "ä¸å€¼è¿™ä¸ªä»·æ ¼ã€‚å¾ˆå¤±æœ›ã€‚",        

        "è´¨é‡ä¼˜ç§€ï¼Œå‘è´§å¾ˆå¿«ã€‚",        # æµ‹è¯•é¢„æµ‹

        "äº§å“ä¸é”™ä½†è¿˜æœ‰æ”¹è¿›ç©ºé—´ã€‚",        test_texts = [

        "å¤ªæ£’äº†ï¼è¶…å‡ºäº†æˆ‘çš„æœŸæœ›ã€‚",            "è¿™æ˜¯ä¸€ä¸ªä»¤äººæƒŠå¹çš„äº§å“!",

        "ææ–™è´¨é‡å·®ï¼Œè®¾è®¡ä¹Ÿä¸å¥½ã€‚",            "æˆ‘è®¨åŒè¿™ä¸ªä¸œè¥¿ã€‚",

        "è¿˜è¡Œï¼Œæœ‰æ”¹è¿›çš„ä½™åœ°ã€‚",            "è¿˜å¯ä»¥å§ï¼Œæˆ‘æƒ³ã€‚",

        "åŠŸèƒ½å¾ˆæ£’ï¼Œç•Œé¢å‹å¥½ã€‚",        ]

        "æµªè´¹é’±ã€‚ä¸è¦ä¹°è¿™ä¸ªã€‚",        

        "å¯é çš„äº§å“ï¼Œæ€§èƒ½ä¸é”™ã€‚",        print("\nğŸ”® æµ‹è¯•é¢„æµ‹:")

        "ç»å¯¹å–œæ¬¢ï¼æœ€å¥½çš„è´­ä¹°å†³å®šã€‚",        predictions = trainer.predict(test_texts)

        "æ²¡æœ‰å°è±¡æ·±åˆ»ã€‚æœŸæœ›æ›´å¥½çš„ã€‚",        

        "ä»·æ ¼åˆç†çš„å¥½äº§å“ã€‚",        for pred in predictions:

        "è´¨é‡ç³Ÿç³•ï¼Œæ”¯æŒä¹Ÿä¸å¥½ã€‚",            print(f"æ–‡æœ¬: '{pred['text']}'")

        "å®Œç¾ç¬¦åˆæˆ‘çš„éœ€æ±‚ã€‚éå¸¸æ»¡æ„ã€‚",            print(f"é¢„æµ‹: {pred['predicted_label']} (ç½®ä¿¡åº¦: {pred['confidence']:.3f})")

    ]            print()

        

    labels = [        print("âœ… æ¼”ç¤ºæˆåŠŸå®Œæˆ!")

        "positive",        

        "negative",     except Exception as e:

        "neutral",        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")

        "positive",        print("è¿™å¯èƒ½æ˜¯ç”±äºèµ„æºé™åˆ¶ã€‚å°è¯•å‡å°‘ batch_size æˆ– num_epochsã€‚")

        "negative",

        "positive",

        "negative",if __name__ == "__main__":

        "positive",    demo_fine_tuning()
        "neutral", 
        "positive",
        "negative",
        "neutral",
        "positive",
        "negative",
        "positive",
        "positive",
        "negative",
        "positive", 
        "negative",
        "positive",
    ]

    return texts, labels


def demo_fine_tuning():
    """æ¼”ç¤ºå¾®è°ƒè¿‡ç¨‹"""
    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»å¾®è°ƒæ¼”ç¤º")
    print("=" * 50)
    
    if not DEPENDENCIES_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œæ— æ³•è¿è¡Œæ¼”ç¤º")
        print("è¯·è¿è¡Œ: pip install torch transformers datasets pandas scikit-learn matplotlib seaborn")
        return
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    texts, labels = create_sample_data()
    print(f"ğŸ“Š åˆ›å»ºäº† {len(texts)} ä¸ªç¤ºä¾‹æ–‡æœ¬ï¼ŒåŒ…å« {len(set(labels))} ä¸ªç±»åˆ«")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    config = FineTuningConfig(
        num_labels=len(set(labels)),
        num_epochs=2,  # æ¼”ç¤ºç”¨ï¼Œå‡å°‘è½®æ•°
        batch_size=8,  # æ¼”ç¤ºç”¨ï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°
    )
    
    trainer = TextClassificationTrainer(config)
    trainer.initialize()
    
    # å‡†å¤‡æ•°æ®
    train_dataset, val_dataset = trainer.prepare_data(texts, labels)
    
    # è®­ç»ƒæ¨¡å‹
    print("\nğŸ‹ï¸ è®­ç»ƒæ¨¡å‹ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    try:
        train_result = trainer.train(train_dataset, val_dataset)
        
        # è¯„ä¼°
        eval_result = trainer.evaluate(val_dataset)
        
        # æµ‹è¯•é¢„æµ‹
        test_texts = [
            "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼",
            "æˆ‘è®¨åŒè¿™ä¸ªä¸œè¥¿ã€‚",
            "è¿˜å¯ä»¥å§ï¼Œæˆ‘è§‰å¾—ã€‚",
        ]
        
        print("\nğŸ”® æµ‹è¯•é¢„æµ‹:")
        predictions = trainer.predict(test_texts)
        
        for pred in predictions:
            print(f"æ–‡æœ¬: '{pred['text']}'")
            print(f"é¢„æµ‹: {pred['predicted_label']} (ç½®ä¿¡åº¦: {pred['confidence']:.3f})")
            print()
        
        # ä¿å­˜æ¨¡å‹
        save_path = "./demo_model"
        trainer.save_model(save_path)
        
        print("âœ… æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        print("è¿™å¯èƒ½æ˜¯ç”±äºèµ„æºé™åˆ¶ã€‚å°è¯•å‡å°‘ batch_size æˆ– num_epochsã€‚")


def simple_demo():
    """ç®€åŒ–æ¼”ç¤ºç‰ˆæœ¬ï¼ˆæ— éœ€è®­ç»ƒï¼‰"""
    print("ğŸ¯ æ–‡æœ¬åˆ†ç±»ç®€å•æ¼”ç¤º")
    print("=" * 30)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    texts, labels = create_sample_data()
    print(f"ğŸ“Š ç¤ºä¾‹æ•°æ®: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œ{len(set(labels))} ä¸ªç±»åˆ«")
    
    # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
    label_counts = {}
    for label in labels:
        label_counts[label] = label_counts.get(label, 0) + 1
    
    print("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in label_counts.items():
        print(f"  {label}: {count} ä¸ªæ ·æœ¬")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆ! å¦‚éœ€å®Œæ•´è®­ç»ƒï¼Œè¯·å®‰è£…ä¾èµ–å¹¶è¿è¡Œ demo_fine_tuning()")


if __name__ == "__main__":
    if DEPENDENCIES_AVAILABLE:
        demo_fine_tuning()
    else:
        simple_demo()