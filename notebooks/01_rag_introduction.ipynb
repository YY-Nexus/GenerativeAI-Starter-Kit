{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation) Introduction\n",
    "\n",
    "üöÄ **Welcome to the RAG Tutorial!**\n",
    "\n",
    "This notebook will guide you through building a complete RAG system from scratch. You'll learn:\n",
    "\n",
    "- What RAG is and why it's important\n",
    "- How to build a document processing pipeline\n",
    "- Vector databases and similarity search\n",
    "- Combining retrieval with generation\n",
    "\n",
    "## What is RAG?\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique that combines:\n",
    "- **Retrieval**: Finding relevant information from a knowledge base\n",
    "- **Generation**: Using that information to generate informed responses\n",
    "\n",
    "This approach allows AI systems to access and use specific knowledge while generating responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this cell first)\n",
    "!pip install sentence-transformers chromadb langchain matplotlib plotly\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from examples.rag.simple_rag import SimpleRAG, RAGConfig\n",
    "from datasets.sample_data import generate_ai_documents\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the RAG System\n",
    "\n",
    "Let's start by creating and configuring our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG configuration\n",
    "config = RAGConfig(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    top_k=3,\n",
    "    collection_name=\"notebook_demo\",\n",
    "    persist_directory=\"./notebook_chroma_db\"\n",
    ")\n",
    "\n",
    "# Initialize RAG system\n",
    "rag = SimpleRAG(config)\n",
    "rag.initialize()\n",
    "\n",
    "print(\"‚úÖ RAG system initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Sample Documents\n",
    "\n",
    "Let's load some sample AI-related documents to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample documents\n",
    "documents_data = generate_ai_documents()\n",
    "\n",
    "# Extract content and metadata\n",
    "documents = [doc['content'] for doc in documents_data]\n",
    "metadata = [{'title': doc['title'], 'category': doc['category'], 'tags': doc['tags']} \n",
    "           for doc in documents_data]\n",
    "\n",
    "print(f\"üìö Loaded {len(documents)} documents:\")\n",
    "for i, doc_data in enumerate(documents_data):\n",
    "    print(f\"{i+1}. {doc_data['title']} (Category: {doc_data['category']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Documents to the RAG System\n",
    "\n",
    "Now let's process and add these documents to our vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to the RAG system\n",
    "rag.add_documents(documents, metadata)\n",
    "\n",
    "print(f\"‚úÖ Successfully added {len(documents)} documents to the RAG system!\")\n",
    "print(f\"üìä Total chunks in database: {rag.collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test RAG Queries\n",
    "\n",
    "Let's test our RAG system with various queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does deep learning work?\",\n",
    "    \"What are the applications of computer vision?\",\n",
    "    \"Explain reinforcement learning\",\n",
    "    \"What is generative AI?\"\n",
    "]\n",
    "\n",
    "# Test each query\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üîç Query {i}: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Search for relevant documents\n",
    "    results = rag.search(query, top_k=2)\n",
    "    \n",
    "    print(f\"\\nüìã Found {len(results)} relevant chunks:\")\n",
    "    for j, result in enumerate(results, 1):\n",
    "        print(f\"\\n{j}. Similarity Score: {1 - result.get('distance', 0):.3f}\")\n",
    "        print(f\"   Content Preview: {result['document'][:200]}...\")\n",
    "        print(f\"   Metadata: {result['metadata']}\")\n",
    "    \n",
    "    # Generate response\n",
    "    context_docs = [result['document'] for result in results]\n",
    "    response = rag.generate_response(query, context_docs)\n",
    "    \n",
    "    print(f\"\\nü§ñ Generated Response:\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Search Results\n",
    "\n",
    "Let's visualize how well our queries match the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze query performance\n",
    "query_analysis = []\n",
    "\n",
    "for query in test_queries:\n",
    "    results = rag.search(query, top_k=5)\n",
    "    similarities = [1 - result.get('distance', 0) for result in results]\n",
    "    query_analysis.append({\n",
    "        'query': query,\n",
    "        'max_similarity': max(similarities) if similarities else 0,\n",
    "        'avg_similarity': np.mean(similarities) if similarities else 0,\n",
    "        'num_results': len(results)\n",
    "    })\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot max similarities\n",
    "queries_short = [q[:30] + '...' if len(q) > 30 else q for q in test_queries]\n",
    "max_sims = [analysis['max_similarity'] for analysis in query_analysis]\n",
    "avg_sims = [analysis['avg_similarity'] for analysis in query_analysis]\n",
    "\n",
    "ax1.bar(range(len(queries_short)), max_sims, alpha=0.7, label='Max Similarity')\n",
    "ax1.bar(range(len(queries_short)), avg_sims, alpha=0.7, label='Avg Similarity')\n",
    "ax1.set_xlabel('Queries')\n",
    "ax1.set_ylabel('Similarity Score')\n",
    "ax1.set_title('Query-Document Similarity Scores')\n",
    "ax1.set_xticks(range(len(queries_short)))\n",
    "ax1.set_xticklabels(queries_short, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot number of results\n",
    "num_results = [analysis['num_results'] for analysis in query_analysis]\n",
    "ax2.bar(range(len(queries_short)), num_results, color='green', alpha=0.7)\n",
    "ax2.set_xlabel('Queries')\n",
    "ax2.set_ylabel('Number of Results')\n",
    "ax2.set_title('Number of Retrieved Documents')\n",
    "ax2.set_xticks(range(len(queries_short)))\n",
    "ax2.set_xticklabels(queries_short, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display analysis summary\n",
    "print(\"\\nüìä Query Analysis Summary:\")\n",
    "for analysis in query_analysis:\n",
    "    print(f\"Query: {analysis['query'][:50]}...\")\n",
    "    print(f\"  Max Similarity: {analysis['max_similarity']:.3f}\")\n",
    "    print(f\"  Avg Similarity: {analysis['avg_similarity']:.3f}\")\n",
    "    print(f\"  Results Found: {analysis['num_results']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Interactive Query Interface\n",
    "\n",
    "Try your own queries with this interactive interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query():\n",
    "    \"\"\"\n",
    "    Interactive query function for testing the RAG system\n",
    "    \"\"\"\n",
    "    print(\"üéØ Interactive RAG Query Interface\")\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user query\n",
    "            query = input(\"\\nüîç Enter your query: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"üëã Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                print(\"‚ö†Ô∏è Please enter a valid query.\")\n",
    "                continue\n",
    "            \n",
    "            # Search and generate response\n",
    "            print(f\"\\nüîç Searching for: '{query}'\")\n",
    "            results = rag.search(query, top_k=3)\n",
    "            \n",
    "            if not results:\n",
    "                print(\"‚ùå No relevant documents found.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nüìã Found {len(results)} relevant chunks:\")\n",
    "            for i, result in enumerate(results, 1):\n",
    "                similarity = 1 - result.get('distance', 0)\n",
    "                print(f\"{i}. Similarity: {similarity:.3f} | {result['document'][:100]}...\")\n",
    "            \n",
    "            # Generate response\n",
    "            context_docs = [result['document'] for result in results]\n",
    "            response = rag.generate_response(query, context_docs)\n",
    "            \n",
    "            print(f\"\\nü§ñ Response:\")\n",
    "            print(\"=\"*60)\n",
    "            print(response)\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Uncomment the line below to start the interactive interface\n",
    "# interactive_query()\n",
    "\n",
    "print(\"üí° Uncomment the last line in this cell to start the interactive interface!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Advanced Features\n",
    "\n",
    "Let's explore some advanced RAG features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Query with different top_k values\n",
    "print(\"üîç Testing different top_k values:\")\n",
    "query = \"What is deep learning?\"\n",
    "\n",
    "for k in [1, 3, 5]:\n",
    "    results = rag.search(query, top_k=k)\n",
    "    print(f\"\\nTop-{k} results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        similarity = 1 - result.get('distance', 0)\n",
    "        print(f\"  {i}. Similarity: {similarity:.3f}\")\n",
    "\n",
    "# 2. Analyze document categories\n",
    "print(\"\\n\\nüìä Document category analysis:\")\n",
    "categories = {}\n",
    "for doc_data in documents_data:\n",
    "    category = doc_data['category']\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "\n",
    "for category, count in categories.items():\n",
    "    print(f\"  {category}: {count} documents\")\n",
    "\n",
    "# 3. Test category-specific queries\n",
    "print(\"\\n\\nüéØ Category-specific query analysis:\")\n",
    "category_queries = {\n",
    "    \"basics\": \"What are the fundamentals of AI?\",\n",
    "    \"advanced\": \"How do advanced AI techniques work?\",\n",
    "    \"applications\": \"What are practical AI applications?\"\n",
    "}\n",
    "\n",
    "for category, query in category_queries.items():\n",
    "    print(f\"\\n{category.upper()} Query: {query}\")\n",
    "    results = rag.search(query, top_k=2)\n",
    "    \n",
    "    for result in results:\n",
    "        doc_category = result['metadata'].get('category', 'unknown')\n",
    "        similarity = 1 - result.get('distance', 0)\n",
    "        print(f\"  Found in '{doc_category}' category (similarity: {similarity:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully built and tested a complete RAG system!\n",
    "\n",
    "### What you learned:\n",
    "1. **RAG Architecture**: Understanding retrieval + generation\n",
    "2. **Document Processing**: Chunking and embedding\n",
    "3. **Vector Search**: Finding relevant information\n",
    "4. **Response Generation**: Creating informed answers\n",
    "5. **Performance Analysis**: Evaluating search quality\n",
    "\n",
    "### Next Steps:\n",
    "1. **Try the multimodal notebook**: Work with images and text together\n",
    "2. **Experiment with fine-tuning**: Customize models for your domain\n",
    "3. **Build a web app**: Create user-friendly interfaces\n",
    "4. **Scale up**: Handle larger document collections\n",
    "\n",
    "### Resources:\n",
    "- üìñ [Documentation](../docs/en/README.md)\n",
    "- üî¨ [Advanced Examples](../examples/)\n",
    "- üõ†Ô∏è [API Server](../automation/api_server.py)\n",
    "\n",
    "Happy learning! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}